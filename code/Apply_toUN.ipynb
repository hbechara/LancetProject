{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Apply_toUN.ipynb","provenance":[{"file_id":"1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX","timestamp":1585323902051},{"file_id":"1dcucJvUOx6kdopjhVIwIdpby6VXhnvns","timestamp":1575478354980},{"file_id":"1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO","timestamp":1575307876986},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1556493831452}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nSU7yERLP_66","colab_type":"text"},"source":["## 1.1. Using Colab GPU for Training\n"]},{"cell_type":"code","metadata":{"id":"DEfSbAA4QHas","colab_type":"code","outputId":"639b868f-5fb7-4766-8961-cfdc317791d1","executionInfo":{"status":"ok","timestamp":1587110341881,"user_tz":-120,"elapsed":2908,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oYsV4H8fCpZ-","colab_type":"code","outputId":"6f1114e3-f21d-49d8-bc4e-0160a5816dd6","executionInfo":{"status":"ok","timestamp":1587110343658,"user_tz":-120,"elapsed":734,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Pw9u6wgqryz","colab_type":"code","outputId":"1a974bfa-bfcc-40e0-fa68-d1d360a42764","executionInfo":{"status":"ok","timestamp":1587110344493,"user_tz":-120,"elapsed":323,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0NmMdkZO8R6q","colab_type":"code","outputId":"56d739e3-f4b7-4ce6-ce7a-5118f58af715","executionInfo":{"status":"ok","timestamp":1587110348457,"user_tz":-120,"elapsed":3319,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"saKXemkCYNnb","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nskPzUM084zL","colab_type":"code","outputId":"d98c754c-b1ec-4673-813a-eaad7a6f7f74","executionInfo":{"status":"ok","timestamp":1587110357173,"user_tz":-120,"elapsed":6641,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from transformers import BertForSequenceClassification, BertTokenizer\n","# Load a trained model and vocabulary that you have fine-tuned\n","main_dir = \"./drive/My Drive/Lancet/\"\n","model_dir = \"model_save_health/\"\n","saved_model_number = 0\n","output_dir = main_dir+model_dir+str(saved_model_number)\n","model = BertForSequenceClassification.from_pretrained(output_dir)\n","tokenizer = BertTokenizer.from_pretrained(output_dir)\n","\n","# Copy the model to the GPU.\n","model.to(device)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"U8nJwPQI4lXQ","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import zipfile\n","downloaded = drive.CreateFile({\"id\": \"13jbSPsFXAj2DWaUdoSxPD6BFm6EFfg0G\"})\n","downloaded.GetContentFile('TXT.zip')\n","with zipfile.ZipFile('TXT.zip', 'r') as zip_ref:\n","    zip_ref.extractall()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VPqmaKV73uY","colab_type":"code","colab":{}},"source":["import os\n","my_directory = 'Session 74 - 2019/'\n","files = os.listdir(my_directory)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SewB2_H6VHpj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"b546e7ec-f5ec-4c7c-9024-ca8024108059","executionInfo":{"status":"ok","timestamp":1587110622704,"user_tz":-120,"elapsed":2277,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}}},"source":["import nltk\n","nltk.download('punkt')\n","#Create dataset of all sentences of that Session\n","li = []\n","for filename in files:\n","  curr_file = my_directory+filename\n","  df = pd.read_csv(open(curr_file), delimiter='\\t', header=None, names=['paragraph'])\n","  li.append(df)\n","df = pd.concat(li, axis=0, ignore_index=True)\n","df=df.dropna()\n","df['sentences'] = df['paragraph'].map(lambda x: nltk.tokenize.sent_tokenize(x))\n","df = df.explode('sentences')\n","df=df.sample(20).reset_index(drop=True)\n","\n","# Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# Create sentence and label lists\n","sentences = df.sentences.values\n","\n","max_len = 0\n","id=[]\n","k=0\n","# For every sentence...\n","for sent in sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","    if len(input_ids) > 100:\n","      id.append(k)\n","    k=k+1\n","\n","\n","print('Max sentence length: ', max_len)\n","sentences = np.delete(sentences,id)\n","len(sentences)\n","\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Number of test sentences: 20\n","\n","Max sentence length:  126\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"0SBww-_55OEL","colab_type":"code","colab":{}},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens\n","                        max_length = 110,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","#For evalualtion on an unlabelled dataset we do not have a labels tensor\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoKBXbpM7A-y","colab_type":"code","outputId":"079f55d5-f5e6-433a-fb46-89361d790e5d","executionInfo":{"status":"ok","timestamp":1587110628523,"user_tz":-120,"elapsed":811,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions = []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","\n","print('    DONE.')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Predicting labels for 19 test sentences...\n","    DONE.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPYte5v37-1l","colab_type":"code","outputId":"bc934e40-7e79-4a07-b038-5e255182b873","executionInfo":{"status":"ok","timestamp":1587111277667,"user_tz":-120,"elapsed":483,"user":{"displayName":"Leonie Neuhaeuser","photoUrl":"","userId":"07779158061885926424"}},"colab":{"base_uri":"https://localhost:8080/","height":751}},"source":["from sklearn.metrics import precision_recall_fscore_support, classification_report, get_scorer, matthews_corrcoef, accuracy_score, cohen_kappa_score, f1_score\n","\n","# Combine the results across all batches. \n","flat_predictions = torch.from_numpy(np.concatenate(predictions, axis=0))\n","\n","#convert to probabilities with sigmoid activation function\n","sigmoid = torch.nn.Sigmoid()\n","prob_predictions = sigmoid(flat_predictions)\n","\n","# For each sample, pick the label (0 or 1) with the higher score.\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","print(\"Probabilities of label 0 (anything) or 1 (health):\")\n","print(prob_predictions)\n","print(\"Predicted label:\")\n","print(flat_predictions)\n","print(\"Sentences:\")\n","print(sentences)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Probabilities of label 0 (anything) or 1 (health):\n","tensor([[0.9844, 0.0063],\n","        [0.9834, 0.0070],\n","        [0.8146, 0.1156],\n","        [0.9395, 0.0262],\n","        [0.9782, 0.0087],\n","        [0.9802, 0.0092],\n","        [0.9699, 0.0142],\n","        [0.9879, 0.0054],\n","        [0.9829, 0.0069],\n","        [0.9816, 0.0071],\n","        [0.9731, 0.0110],\n","        [0.9862, 0.0057],\n","        [0.9840, 0.0065],\n","        [0.9731, 0.0105],\n","        [0.9849, 0.0078],\n","        [0.9863, 0.0062],\n","        [0.9548, 0.0182],\n","        [0.9693, 0.0151],\n","        [0.5827, 0.3263]])\n","Predicted label:\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","Sentences:\n","['New opportunities have emerged for the region following the first informal consultations at the highest level held in our capital last year.'\n"," 'This went on forever, a bit like the experience of Brexit in the United Kingdom, if some of our parliamentarians had their way.'\n"," '“I take this opportunity to reaffirm from this rostrum my country’s commitment to continuing to work towards sustainable development in order to achieve social inclusion and the reduction of inequalities, in particular by encouraging effective political impact through the strengthening of dialogue on social development issues, which will ensure the successful implementation of the 2030 Agenda.'\n"," 'We said then, as we say now almost nine months later, that the time for dialogue can never be over in a world that wants peace and prosperity.'\n"," 'My country has always been a steadfast supporter of preventive diplomacy and mediation on the global stage.'\n"," 'We should have teams of well-equipped and trained disaster experts ready to rush to disaster areas.'\n"," 'Either it must respect the Astana agreement and the bilateral counter-terrorism agreements between our two countries, in order to guarantee the security of its borders, and withdraw its forces from Syrian territories, or it must choose to be the aggressor and occupier and face the consequences.'\n"," 'Today’s challenges and threats are no less dangerous.'\n"," 'The international community will ignore us at its own peril.'\n"," 'We must redouble our efforts.'\n"," 'Peace, justice, equality and non-discrimination are fundamental rights that must be fully realized if we are to succeed in building inclusive societies.'\n"," 'The words he wrote a few hours before he was killed in battle are particularly relevant today:'\n"," 'In Japan, a new Emperor has acceded to the imperial throne, and the ceremony at which His Majesty will declare this fact to both domestic and international audiences will soon take place, on 22 October.'\n"," 'We have no time to lose.'\n"," 'Only verifiable results matter and only concrete deeds serve as a credible example to others.'\n"," 'Further, the withdrawal of correspondent banking services undermines the region’s efforts to consolidate a global partnership that will achieve the Sustainable Development Goals.'\n"," 'It is this same and singular Cuban Revolution that was commanded by Fidel Castro Ruz and is now headed by the First Secretary of the Communist Party of Cuba, Raul Modesto Castro Ruz, and President Miguel Diaz Canel Bermudez.'\n"," 'While development requires a minimum of peace, it is equally true that peace cannot prosper in the enclaves of abject poverty and insecurity, which present a distressing picture to the world.'\n"," 'The proper responses to those challenges are a reinvigorated Assembly, a recommitment to principle and international law and a renewed focus on the diverse voices of all Members of our noble institution.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gI5crqhu8y_1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}